# モデルアーキテクチャ

このプロジェクトでは、エンコーダ-デコーダ構造とアテンション機構を組み合わせた深層学習モデルを使用しています。

## 全体構造

```
+---------------+    +----------------+    +----------------+
|               |    |                |    |                |
|  画像エンコーダ  |--->|  アテンション  |--->|    デコーダ    |---> キャプション
|   (ResNet-50)  |    |    機構      |    |    (LSTM)      |
|               |    |                |    |                |
+---------------+    +----------------+    +----------------+
```

## エンコーダ

エンコーダは事前学習済みのResNet-50を使用しています：

- 最終分類層を除去し、特徴マップを抽出
- 適応的平均プーリングにより特徴マップのサイズを調整
- 出力：14×14×2048の特徴マップ（196の512次元ベクトル）

## アテンション機構

ソフトアテンションメカニズムにより、デコーダが画像の関連領域に注目できるようにしています：

- デコーダの隠れ状態と各画像領域の特徴間のアラインメントスコアを計算
- ソフトマックス関数によりアテンション重みに変換
- アテンション重みを使用して特徴をコンテキストベクトルとして集約

## デコーダ

LSTMベースのデコーダが単語を順次生成します：

- 単語埋め込み層により単語をベクトル表現に変換
- LSTMセルによる隠れ状態の更新
- アテンションゲートによりコンテキストベクトルの重要度を調整
- 全結合層とソフトマックス関数により次の単語を予測